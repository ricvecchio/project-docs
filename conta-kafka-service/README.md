# üöÄ Guia Oficial de Deploy Local com Docker

Este projeto utiliza um ambiente completo de microservi√ßos Java Spring Boot orquestrados via Docker Compose, com os seguintes componentes:
![Diagrama](https://github.com/ricvecchio/project-docs/blob/main/images/spring-kafka-container.png)

üêò PostgreSQL ‚Äî Banco de dados relacional  
üß† Zookeeper ‚Äî Coordena√ß√£o e registro de servi√ßos para o Kafka  
üîÑ Kafka Broker ‚Äî Sistema de mensageria distribu√≠da   
üí≥ Conta Service ‚Äî Microservi√ßo principal para opera√ß√µes de conta  
üì¨ Kafka Service ‚Äî Microservi√ßo para consumo e publica√ß√£o de mensagens Kafka

---

### üîÑ Fluxo de Mensagens Kafka ‚Äî Comunica√ß√£o entre os Microservi√ßos

A arquitetura de mensageria do projeto √© baseada no **Apache Kafka**, respons√°vel como um mecanismo de **mensageria ass√≠ncrona** entre dois microsservi√ßos:
üëâ o **conta-service** (produtor) e o **kafka-service** (consumidor).
```text
+-------------------+        +-------------------+        +-------------------+        +---------------------+
|                   |        |                   |        |                   |        |                     |
|   Conta Service   | -----> |   Kafka Broker    | -----> |   Kafka Service   | -----> |     PostgreSQL      |
|  (Produz eventos) |        | (Gerencia t√≥picos)|        | (Consome eventos) |        |   (Persist√™ncia)    |
|                   |        |                   |        |                   |        |                     |
+--------+----------+        +---------+---------+        +---------+---------+        +----------+----------+
         |                             |                            |                             |
         | 1Ô∏è‚É£ POST /api/contas/abrir   |                            |                             |
         |    Envia evento (Producer)  |                            |                             |         
         |---------------------------->|                            |                             |
         |                             |                            |                             |
         | 2Ô∏è‚É£ kafkaTemplate.send()     |                            |                             |
         |---------------------------->| 3Ô∏è‚É£ Armazena mensagem       |                             |
         |                             |    no t√≥pico               |                             |
         |                             |--------------------------->| 4Ô∏è‚É£ @KafkaListener consome   |
         |                             |                            |    e processa mensagem      |
         |                             |                            |---------------------------> |
         |                             |                            | 5Ô∏è‚É£ Salva Cliente e Conta    |
         |                             |                            |    no PostgreSQL            |
```

---

### üß© Vis√£o Geral do Fluxo Kafka

1. O **usu√°rio faz uma requisi√ß√£o HTTP** `(POST /api/contas/abrir)` para abrir uma nova conta.
2. O **conta-service** transforma essa requisi√ß√£o em uma **mensagem JSON** e **publica no t√≥pico Kafka** (`conta.aberturas.topic`).
3. O **kafka-service** escuta esse t√≥pico atrav√©s de um **@KafkaListener, consome a mensagem**, e **cria/atualiza o cliente e a conta no banco PostgreSQL.**
4. Todo esse processo ocorre **de forma ass√≠ncrona e desacoplada**, sem depend√™ncia direta entre os dois servi√ßos.

---

### üîÑ Componentes do Fluxo

| **Componente**         | **Tipo**         | **Responsabilidade Principal**                                    |
|-------------------------|------------------|-------------------------------------------------------------------|
| `conta-service`         | Producer         | Envia mensagens Kafka com dados de abertura de conta |
| `KafkaProducerConfig`   | Configura√ß√£o     | Define propriedades do produtor Kafka                             |
| `Kafka Broker`        | Middleware       | Armazena e distribui mensagens entre servi√ßos                     |
| `kafka-service`         | Consumer         | L√™ mensagens e executa persist√™ncia no banco                      |
| `KafkaConsumerConfig`   | Configura√ß√£o     | Controla comportamento e pol√≠ticas de leitura                     |
| `PostgreSQL`          | Banco de dados   | Persist√™ncia final de Cliente e Conta                             |

---

### üß≠ Estrutura do Projeto

```text
api-funcoes-teste-spring/
‚îú‚îÄ‚îÄ .github/workflows/deploy(vps/test))
‚îú‚îÄ‚îÄ .mvn/wrapper/maven-wrapper.properties
‚îú‚îÄ‚îÄ infra/
‚îÇ   ‚îú‚îÄ‚îÄ .env(dev/prod)
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ pom.xml
‚îî‚îÄ‚îÄ README.md

conta-service/
‚îú‚îÄ‚îÄ .github/workflows/deploy-conta.yml
‚îú‚îÄ‚îÄ .mvn/wrapper/maven-wrapper.jar
‚îú‚îÄ‚îÄ src/main/
‚îÇ   ‚îú‚îÄ‚îÄ java/com/funcoes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controller/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repository/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ContaServiceApplication.java
‚îÇ   ‚îî‚îÄ‚îÄ resources/application.properties
‚îú‚îÄ‚îÄ target/conta-service-1.0.0.jar
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ pom.xml

kafka-service/
‚îú‚îÄ‚îÄ .github/workflows/deploy-kafka.yml
‚îú‚îÄ‚îÄ .mvn/wrapper/maven-wrapper.jar
‚îú‚îÄ‚îÄ src/main/
‚îÇ   ‚îú‚îÄ‚îÄ java/com/funcoes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ consumer/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controller/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repository/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ KafkaServiceApplication.java
‚îÇ   ‚îî‚îÄ‚îÄ resources/application.properties
‚îú‚îÄ‚îÄ target/kafka-service-1.0.0.jar
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ pom.xml
```
---

## ‚úÖ Benef√≠cios da Arquitetura com Kafka

- **Desacoplamento:** o `conta-service` n√£o depende da disponibilidade do `kafka-service`.
- **Escalabilidade:** m√∫ltiplos consumidores podem ler o mesmo t√≥pico em paralelo.
- **Toler√¢ncia a falhas:** mensagens permanecem armazenadas at√© o consumo bem-sucedido.
- **Consist√™ncia eventual:** o estado do sistema se propaga via eventos Kafka.

---

## üß© Vis√£o Geral do Fluxo Kafka

O usu√°rio faz uma requisi√ß√£o HTTP (`POST /api/contas/abrir`) para abrir uma nova conta.

O **conta-service** transforma essa requisi√ß√£o em uma **mensagem JSON** e publica no t√≥pico Kafka (`conta.aberturas.topic`).

O **kafka-service** escuta esse t√≥pico atrav√©s de um `@KafkaListener`, consome a mensagem e cria/atualiza o cliente e a conta no banco **PostgreSQL**.

Todo esse processo ocorre de forma **ass√≠ncrona e desacoplada**, sem depend√™ncia direta entre os dois servi√ßos.

---

## ‚öôÔ∏è Fun√ß√µes e Responsabilidades do Kafka ‚Äî Passo a Passo

---

### **1. Produ√ß√£o da Mensagem (Producer)**

üìç **Local:** `conta-service ‚Üí ContaService.java`

**Fun√ß√£o do Kafka aqui:**
- Enviar mensagens para o t√≥pico Kafka definido em `application.properties` (`conta.aberturas.topic`).
- Garantir entrega confi√°vel e segura (usando `acks=all` e `retries=3`).

**Onde acontece:**
```java
kafkaTemplate.send(contaAberturasTopic, request.getCpf(), payload);
```
**Descri√ß√£o t√©cnica:**

- `KafkaTemplate` √© o componente que **envia mensagens**.
- O m√©todo `.send()` publica a mensagem no **t√≥pico**.
- A `key` (CPF) garante **particionamento consistente** ‚Äî todas as mensagens do mesmo cliente v√£o para a mesma parti√ß√£o.
- O `payload` √© um **JSON** com os dados da requisi√ß√£o (`AbrirContaRequest`).

**Configura√ß√£o usada:**  
üìç **Arquivo:** `KafkaProducerConfig.java`

Define propriedades do producer:
- Servidor Kafka (`bootstrap-servers`)
- Serializadores (`StringSerializer`)
- Confirma√ß√£o de envio (`ACKS_CONFIG = all`)
- Tentativas de reenvio (`RETRIES_CONFIG = 3`)

---

### **2Ô∏è‚É£ Transporte da Mensagem (Broker)**

üìç **Local:*** Entre os dois servi√ßos ‚Äî mediado pelo ***Kafka Broker**

**Fun√ß√µes:**
- Atuar como **middleware de mensageria**, armazenando e entregando as mensagens de forma confi√°vel. 
- Garantir **durabilidade e ordena√ß√£o** por parti√ß√£o. 
- Permitir que o consumidor processe as mensagens mesmo que o produtor ou o consumidor estejam temporariamente offline.

**Detalhes t√©cnicos:**
- O Kafka **persiste a mensagem em disco** no cluster.
- Mant√©m o **offset de leitura** para cada grupo de consumidores.
- Caso o `kafka-service` esteja fora do ar, as mensagens **ficam retidas** at√© serem consumidas.

**Componente principal:**
- **T√≥pico:** `conta.aberturas.topic`
- **Mensagem:** JSON com dados da requisi√ß√£o de abertura de conta

---

### **3Ô∏è‚É£ Consumo da Mensagem (Consumer)**

üìç **Local:** `kafka-service ‚Üí ContaConsumer.java`

**Fluxo:**
- **Entregar mensagens** publicadas no t√≥pico (conta.aberturas.topic) para o servi√ßo consumidor.
- Controlar o **offset** (posi√ß√£o de leitura).
- Permitir **reprocessamento** em caso de erro, pois o commit autom√°tico est√° desativado.

**Onde acontece:**
```java
@KafkaListener(topics = "${conta.aberturas.topic}", groupId = "kafka-service")
public void consume(String message) { ... }
```

**Descri√ß√£o t√©cnica:**
- O `@KafkaListener` faz o subscribe ao t√≥pico e **aciona automaticamente** o m√©todo `consume()` ao receber novas mensagens.
- O `groupId` (`kafka-service`) garante que esse consumidor **fa√ßa parte de um grupo l√≥gico,** evitando leitura duplicada por outros servi√ßos iguais.
- A mensagem JSON √© **desserializada** via `ObjectMapper` e usada para:
  - Criar ou atualizar o `Cliente` no banco.
  - Criar uma nova `Conta` associada ao cliente.

---

### **4Ô∏è‚É£ Persist√™ncia no Banco de Dados**

üìç **Local:** `kafka-service ‚Üí ContaConsumer.java`

**Fun√ß√£o do Kafka aqui:**
- Embora o Kafka n√£o grave diretamente no banco, ele **dispara o evento** que inicia a persist√™ncia. 
- O consumidor √© respons√°vel por:
  - Interpretar a mensagem Kafka.
  - Executar opera√ß√µes no banco PostgreSQL via `ClienteRepository` e `ContaRepository`.

**Fluxo dentro do consumidor:**
```java
Cliente cliente = clienteRepository.findByCpf(cpfLimpo)
        .orElseGet(() -> clienteRepository.save(new Cliente(request.getNomeCliente(), cpfLimpo)));

Conta conta = new Conta();
conta.setTipo(request.getTipoConta());
        conta.setStatus(StatusConta.ATIVA);
conta.setCliente(cliente);
contaRepository.save(conta);
```

---

### **5Ô∏è‚É£ Persist√™ncia no Banco de Dados**

üìç **Local:** `KafkaConsumerConfig.java`

**Fun√ß√£o:**
- Definir como o consumidor Kafka se conecta, processa e gerencia mensagens.

**Principais par√¢metros:** 

| Configura√ß√£o                 | Fun√ß√£o                                                         |
| ---------------------------- | -------------------------------------------------------------- |
| `bootstrap-servers`          | Endere√ßo do cluster Kafka                                      |
| `group.id`                   | Identifica o grupo de consumidores                             |
| `enable.auto.commit=false`   | Desativa commit autom√°tico (maior controle de reprocessamento) |
| `auto.offset.reset=earliest` | Come√ßa a consumir desde o in√≠cio caso n√£o haja offset salvo    |
| `poll.timeout=1500`          | Tempo m√°ximo de espera para novas mensagens                    |

---

## üß† Fun√ß√µes do Kafka no Projeto

| **Etapa** | **Servi√ßo**       | **Fun√ß√£o Kafka**                          | **Localiza√ß√£o**                                  |
|------------|-------------------|--------------------------------------------|--------------------------------------------------|
| 1Ô∏è‚É£ Produ√ß√£o de mensagem | `conta-service`   | Publicar evento de abertura de conta        | `ContaService.abrirConta()`                     |
| 2Ô∏è‚É£ Transporte ass√≠ncrono | `Kafka Broker`  | Armazenar e rotear mensagens                | Servidor Kafka                                  |
| 3Ô∏è‚É£ Consumo de mensagem   | `kafka-service`   | Escutar e processar eventos                 | `ContaConsumer.consume()`                       |
| 4Ô∏è‚É£ Persist√™ncia          | `kafka-service`   | Converter evento em a√ß√£o no BD              | `ClienteRepository` e `ContaRepository`         |
| 5Ô∏è‚É£ Configura√ß√£o t√©cnica  | **Ambos**         | Controlar comportamento de producer e consumer | `KafkaProducerConfig`, `KafkaConsumerConfig` |

---

## üîç Conclus√£o

O Kafka no seu projeto atua como um **barramento de eventos** entre microsservi√ßos, permitindo:
- **Desacoplamento total** entre `conta-service` e `kafka-service`.
- **Escalabilidade horizontal** (v√°rios consumidores por grupo).
- **Toler√¢ncia a falhas** (mensagens persistidas at√© consumo).
- **Consist√™ncia eventual** entre servi√ßos.

---

## üü¢ In√≠cio: Passo a passo para subir localmente com Docker

---

### 1Ô∏è‚É£ Pr√©-requisitos
- Docker e Docker Compose instalados.
- Java 21 + Maven (caso queira rodar manualmente).
- Porta 5432 (PostgreSQL) e 9092 (Kafka) livres.

---

### 2Ô∏è‚É£ Limpeza Completa do Ambiente Docker
Antes de subir o ambiente, **limpe todas as imagens, containers e redes antigas** para evitar conflitos:

```bash
docker stop $(docker ps -aq) && \
docker rm -f $(docker ps -aq) && \
docker rmi -f $(docker images -aq) && \
docker volume rm -f $(docker volume ls -q) && \
docker network rm $(docker network ls -q | grep -v "bridge\|host\|none") && \
docker builder prune -af
```
‚ö†Ô∏è **Aten√ß√£o:** Esse comando remove **tudo** do Docker (containers, volumes, imagens e redes personalizadas).
Use apenas se deseja come√ßar do zero.

---

### 3Ô∏è‚É£ Verifica√ß√£o de Portas Livres

Certifique-se de que as seguintes portas **n√£o est√£o em uso** no seu sistema:

| Servi√ßo | Porta | Descri√ß√£o |
|---------|-------|-----------|
| PostgreSQL | 5432 | Banco de dados |
| Zookeeper | 2181 | Coordena√ß√£o Kafka |
| Kafka Broker | 29092 | Comunica√ß√£o Kafka |
| Conta Service | 8081 | API REST |
| Kafka Service | 8082 | API REST |

Verifique se h√° processos ativos nas portas (no macOS):

```bash
sudo lsof -i :5432
sudo lsof -i :2181
sudo lsof -i :9092
sudo lsof -i :8081
sudo lsof -i :8082
```

Para liberar uma porta ocupada:
```bash
sudo kill -9 <PID>
```
---

### 4Ô∏è‚É£ Navega√ß√£o local do projeto

Acesse a pasta de infraestrutura local no terminal:

```bash
cd ~/"Projetos/Projeto para Estudos (Frontend + Backend)/api-funcoes-teste-spring/infra"
```
---

### 5Ô∏è‚É£ Subindo o Ambiente Completo

Com o **Docker Desktop** aberto e em execu√ß√£o, execute:

```bash
docker compose --env-file .env up -d --build
```

Esse comando vai:
1. Criar a **rede** `microservices-net`
2. Subir o **PostgreSQL**, **Zookeeper** e **Kafka Broker**
3. Construir as imagens do `conta-service` e `kafka-service`
4. Iniciar todos os containers em segundo plano

---

### 6Ô∏è‚É£ Verificando o Status dos Containers

Ap√≥s alguns minutos (aguarde os health checks internos), execute:

```bash
docker ps
```

Sa√≠da esperada (exemplo):
```nginx
CONTAINER ID   NAME             STATUS                    PORTS
abc123         conta-service    Up (healthy)  0.0.0.0:8081->8080/tcp
def456         kafka-service    Up (healthy)  0.0.0.0:8082->8080/tcp
ghi789         kafka-broker     Up (healthy)  0.0.0.0:9092->9092/tcp
jkl101         zookeeper        Up (healthy)  0.0.0.0:2181->2181/tcp
mno112         postgres-db      Up (healthy)  0.0.0.0:5432->5432/tcp
```

---

### 7Ô∏è‚É£ Teste Completo (Smoke Test)
Ap√≥s subir o ambiente, rode os health checks:
```bash
curl -s http://localhost:8081/actuator/health
curl -s http://localhost:8082/actuator/health
```
Ambos devem retornar `"status": "UP"`

---

### üíæ üêû Logs e Debug

Para visualizar logs de um servi√ßo espec√≠fico:

```bash
docker logs -f conta-service
```
ou 
```bash
docker logs -f kafka-service
```

---

## üåê Endpoints para Teste no Insomnia

### üåø Conta Service (`http://localhost:8081`)

---

1Ô∏è‚É£ **Criar Conta** - POST `/api/contas/abrir`
- **Body:** (JSON)
```json
{
  "nomeCliente": "Ricardo Teste",
  "cpf": "123.456.789-01",
  "tipoConta": "CORRENTE"
}
```
‚úÖ **Resposta:**
```json
{
  "mensagem": "‚úÖ Solicita√ß√£o de abertura de conta processada!",
  "status": "ACCEPTED",
  "timestamp": "2025-10-20T14:12:08.304246174Z"
}
```

---

2Ô∏è‚É£ **Listar Endpoints** - GET `/api/endpoints`

‚úÖ **Resposta:**
```json
[
  {
    "path": "/",
    "methods": "GET",
    "controller": "HealthController",
    "methodName": "home"
  },
  {
    "path": "/api/contas/abrir",
    "methods": "POST",
    "controller": "ContaController",
    "methodName": "abrirConta"
  },
  {
    "path": "/api/endpoints",
    "methods": "GET",
    "controller": "EndpointController",
    "methodName": "listarEndpoints"
  },
  {
    "path": "/health",
    "methods": "GET",
    "controller": "HealthController",
    "methodName": "health"
  }
]
```

---

3Ô∏è‚É£ **Actuator Health:** - GET `/actuator/health`

‚úÖ **Resposta:**
```json
{
  "status": "UP",
  "groups": [
    "liveness",
    "readiness"
  ]
}
```
---

4Ô∏è‚É£ **Health Check:** - GET `/health`

‚úÖ **Resposta:**
```json
{
  "service": "conta-service",
  "version": "1.0.0",
  "status": "UP",
  "timestamp": "2025-10-20T14:12:46.533994678"
}
```
---

### üåø Kafka Service (`http://localhost:8082`)

1Ô∏è‚É£ **Listar Contas** - GET `/api/contas`

‚úÖ **Resposta:**
```json
[
  {
    "id": 1,
    "tipo": "CORRENTE",
    "status": "ATIVA",
    "cliente": {
      "id": 1,
      "nome": "Ricardo Teste Post 1",
      "cpf": "12345678901"
    }
  },
  {
    "id": 2,
    "tipo": "CORRENTE",
    "status": "ATIVA",
    "cliente": {
      "id": 1,
      "nome": "Ricardo Teste Post 1",
      "cpf": "12345678901"
    }
  }
]
```

---

2Ô∏è‚É£ **Actuator Health** - GET `/actuator/health`

‚úÖ **Resposta:**
```json
{
  "status": "UP",
  "groups": [
    "liveness",
    "readiness"
  ]
}
```

---

3Ô∏è‚É£ **Health Check:** - GET `/health`

‚úÖ **Resposta:**
```json
{
  "service": "kafka-service",
  "version": "1.0.0",
  "status": "UP",
  "timestamp": "2025-10-20T14:12:50.149249971"
}
```
---

## üß† Dicas de Troubleshooting
- Caso um servi√ßo fique em `unhealthy`, use:
```bash
docker inspect <nome_container> | grep -A 10 "Health"
```
- Verifique logs:
```bash
docker logs <nome_container>
```
- Reinicie um container individual:
```bash
docker restart conta-service
```
- Para reconstruir as imagens sem cache:
```bash
docker compose build --no-cache
```

---

## üßπ Encerrando o Ambiente
Para **parar e remover tudo** (containers, redes e volumes):
```bash
docker compose down -v --remove-orphans
```
Se quiser limpar completamente o cache e imagens:
```bash
docker system prune -af
```

---
